<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link
      rel="stylesheet"
      href="{{ url_for('static', filename='style.css') }}"
    />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.7.2/font/bootstrap-icons.css"
      rel="stylesheet"
    />
    <title>Speech Recognition System</title>
  </head>
  <body>
    <div class="conainermain">
      <div class="headingcontainer">
        <h1 class="mainheading">SPEECH RECOGNITION SYSTEM</h1>
      </div>
      <div class="container">
        <button id="recordButton"><i class="bi bi-mic-fill"></i>Record</button>
        <p id="status">Status: Idle</p>
        <textarea
          onclick="reloadAudio()"
          id="transcript"
          placeholder="Transcribed Text Will appear here"
        ></textarea>
      </div>
    </div>

    <script>
      const recordButton = document.getElementById("recordButton");
      const status = document.getElementById("status");
      const transcriptInput = document.getElementById("transcript");

      let mediaRecorder;
      let audioChunks = [];

      recordButton.addEventListener("click", async () => {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          alert("getUserMedia is not supported in this browser.");
          return;
        }

        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm" });

          mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
          };

          mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
            const arrayBuffer = await audioBlob.arrayBuffer();
            const audioContext = new AudioContext({ sampleRate: 16000 });

            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            const offlineAudioContext = new OfflineAudioContext(
              1,
              audioBuffer.length,
              16000
            );
            const source = offlineAudioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(offlineAudioContext.destination);
            source.start(0);

            const renderedBuffer = await offlineAudioContext.startRendering();
            const wavBlob = createWavFile(renderedBuffer);

            uploadAudio(wavBlob);
          };

          mediaRecorder.start();
          status.textContent = "Status: Recording";
          recordButton.disabled = true;
          recordButton.style.display = "none";

          // Stop recording after 3 seconds
          setTimeout(() => {
            mediaRecorder.stop();
            status.textContent = "Status: Stopped";
            recordButton.disabled = false;
            recordButton.style.display = "block";
          }, 3000);
        } catch (err) {
          console.error("Error accessing media devices.", err);
          alert("Error accessing media devices: " + err.message);
        }
      });

      function createWavFile(buffer) {
        const numOfChan = buffer.numberOfChannels;
        const length = buffer.length * numOfChan * 2 + 44;
        const bufferArray = new ArrayBuffer(length);
        const view = new DataView(bufferArray);
        const channels = [];
        let sample;
        let offset = 0;
        let pos = 0;

        // Write WAV file header
        setUint32(0x46464952); // "RIFF"
        setUint32(length - 8); // file length - 8
        setUint32(0x45564157); // "WAVE"
        setUint32(0x20746d66); // "fmt " chunk
        setUint32(16); // length = 16
        setUint16(1); // PCM (uncompressed)
        setUint16(numOfChan);
        setUint32(buffer.sampleRate);
        setUint32(buffer.sampleRate * 2 * numOfChan); // avg. bytes/sec
        setUint16(numOfChan * 2); // block-align
        setUint16(16); // 16-bit (hardcoded in this demo)
        setUint32(0x61746164); // "data" - chunk
        setUint32(length - pos - 4); // chunk length

        // Write interleaved data
        for (let i = 0; i < buffer.numberOfChannels; i++)
          channels.push(buffer.getChannelData(i));

        while (pos < length) {
          for (let i = 0; i < numOfChan; i++) {
            // interleave channels
            sample = Math.max(-1, Math.min(1, channels[i][offset])); // clamp
            sample = (sample < 0 ? sample * 0x8000 : sample * 0x7fff) | 0; // scale to 16-bit signed int
            view.setInt16(pos, sample, true); // write 16-bit sample
            pos += 2;
          }
          offset++; // next source sample
        }

        return new Blob([bufferArray], { type: "audio/wav" });

        function setUint16(data) {
          view.setUint16(pos, data, true);
          pos += 2;
        }

        function setUint32(data) {
          view.setUint32(pos, data, true);
          pos += 4;
        }
      }

      async function uploadAudio(blob) {
        const formData = new FormData();
        formData.append("audio", blob, "recording.wav");

        try {
          const response = await fetch("/upload", {
            method: "POST",
            body: formData,
          });

          if (response.ok) {
            status.textContent = "Status: Upload successful";
            const transcriptionResponse = await fetch("/transcribe");
            const transcriptionData = await transcriptionResponse.json();
            transcriptInput.value = transcriptionData.transcript;
          } else {
            status.textContent = "Status: Upload failed";
          }
        } catch (error) {
          status.textContent = "Status: Upload error";
          console.error("Upload error:", error);
        }
      }
    </script>
  </body>
</html>
